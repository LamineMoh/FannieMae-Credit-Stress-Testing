{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRISP-DM Analysis: Fannie Mae 2008Q1 Stress Testing\n",
    "\n",
    "## Credit Default Risk Modeling During the 2008 Financial Crisis\n",
    "\n",
    "**Author:** Data Science Team  \n",
    "**Date:** December 2025  \n",
    "**Dataset:** Fannie Mae Single-Family Loan Performance Data - Q1 2008\n",
    "\n",
    "---\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook implements the complete **CRISP-DM** (Cross-Industry Standard Process for Data Mining) methodology to analyze mortgage loan performance during the 2008 financial crisis stress period.\n",
    "\n",
    "### CRISP-DM Phases:\n",
    "1. **Business Understanding** - Define objectives and success criteria\n",
    "2. **Data Understanding** - Explore and describe the data\n",
    "3. **Data Preparation** - Clean and transform data for modeling\n",
    "4. **Modeling** - Train classification models\n",
    "5. **Evaluation** - Assess model performance\n",
    "6. **Deployment** - Generate reports and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    roc_curve, precision_recall_curve, f1_score, accuracy_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 200)\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these paths as needed\n",
    "# =============================================================================\n",
    "\n",
    "DATA_PATH = r\"2008Q1.csv\"  # Path to the data file\n",
    "OUTPUT_DIR = r\".\"          # Output directory for results\n",
    "SAMPLE_SIZE = 500000       # Number of records to analyze\n",
    "RANDOM_STATE = 42          # Random seed for reproducibility\n",
    "\n",
    "# Fannie Mae Performance File Column Names (first 30 columns)\n",
    "COLUMN_NAMES = [\n",
    "    'loan_sequence_number',         # 0 - Loan Identifier\n",
    "    'monthly_reporting_period',     # 1 - Monthly Reporting Period (YYYYMM)\n",
    "    'current_actual_upb',           # 2 - Current Actual UPB\n",
    "    'current_loan_delinquency',     # 3 - Current Loan Delinquency Status (TARGET)\n",
    "    'loan_age',                     # 4 - Loan Age\n",
    "    'remaining_months_maturity',    # 5 - Remaining Months to Legal Maturity\n",
    "    'repurchase_flag',              # 6 - Repurchase Flag\n",
    "    'modification_flag',            # 7 - Modification Flag\n",
    "    'zero_balance_code',            # 8 - Zero Balance Code\n",
    "    'zero_balance_date',            # 9 - Zero Balance Effective Date\n",
    "    'current_interest_rate',        # 10 - Current Interest Rate\n",
    "    'current_deferred_upb',         # 11 - Current Deferred UPB\n",
    "    'due_date_last_paid',           # 12 - Due Date of Last Paid Installment\n",
    "    'mi_recoveries',                # 13 - MI Recoveries\n",
    "    'net_sales_proceeds',           # 14 - Net Sales Proceeds\n",
    "    'non_mi_recoveries',            # 15 - Non MI Recoveries\n",
    "    'expenses',                     # 16 - Expenses\n",
    "    'legal_costs',                  # 17 - Legal Costs  \n",
    "    'maintenance_costs',            # 18 - Maintenance and Preservation Costs\n",
    "    'taxes_insurance_due',          # 19 - Taxes and Insurance\n",
    "    'miscellaneous_expenses',       # 20 - Miscellaneous Expenses\n",
    "    'actual_loss_calculation',      # 21 - Actual Loss Calculation\n",
    "    'modification_cost',            # 22 - Modification Cost\n",
    "    'step_modification_flag',       # 23 - Step Modification Flag\n",
    "    'deferred_payment_mod',         # 24 - Deferred Payment Plan\n",
    "    'estimated_ltv',                # 25 - Estimated Loan-to-Value\n",
    "    'zero_balance_removal_upb',     # 26 - Zero Balance Removal UPB\n",
    "    'delinquent_accrued_interest',  # 27 - Delinquent Accrued Interest\n",
    "    'delinquency_due_disaster',     # 28 - Delinquency Due to Disaster\n",
    "    'borrower_assistance_status',   # 29 - Borrower Assistance Status Code\n",
    "]\n",
    "\n",
    "# Add remaining columns as generic names (up to 110)\n",
    "for i in range(30, 110):\n",
    "    COLUMN_NAMES.append(f'col_{i}')\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  - Data Path: {DATA_PATH}\")\n",
    "print(f\"  - Sample Size: {SAMPLE_SIZE:,}\")\n",
    "print(f\"  - Random State: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1: Business Understanding\n",
    "\n",
    "## 1.1 Business Objective\n",
    "\n",
    "The goal of this analysis is to **predict mortgage loan defaults** during the Q1 2008 stress period (peak of the financial crisis). This supports:\n",
    "\n",
    "- **Stress Testing**: Evaluate portfolio risk under crisis conditions\n",
    "- **Risk Assessment**: Identify high-risk loans for proactive management\n",
    "- **Regulatory Compliance**: Meet stress testing requirements\n",
    "\n",
    "## 1.2 Target Variable Definition\n",
    "\n",
    "| Status | Description | Classification |\n",
    "|--------|-------------|----------------|\n",
    "| 0 | Current (not delinquent) | No Default |\n",
    "| 1-2 | 30-60 days delinquent | No Default |\n",
    "| 3+ | 90+ days delinquent | **DEFAULT** |\n",
    "| RA | REO Acquisition | **DEFAULT** |\n",
    "\n",
    "## 1.3 Success Criteria\n",
    "\n",
    "- **AUC-ROC > 0.70**: Acceptable predictive power\n",
    "- **High Recall**: Minimize missed defaults (false negatives)\n",
    "- **Interpretability**: Understand risk drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Business Understanding Summary\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: BUSINESS UNDERSTANDING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "BUSINESS OBJECTIVE:\n",
    "-------------------\n",
    "• Predict mortgage loan defaults during Q1 2008 (financial crisis peak)\n",
    "• Support stress testing and risk assessment for credit portfolios\n",
    "• Identify key risk drivers to inform lending policies\n",
    "\n",
    "TARGET VARIABLE:\n",
    "----------------\n",
    "• current_loan_delinquency: Loan delinquency status\n",
    "  - 0 = Current (not delinquent)\n",
    "  - 1-2 = 30-60 days delinquent\n",
    "  - 3+ = 90+ days delinquent (DEFAULT - our target)\n",
    "  - RA = REO Acquisition (DEFAULT)\n",
    "\n",
    "SUCCESS CRITERIA:\n",
    "-----------------\n",
    "• AUC-ROC > 0.70 (acceptable predictive power)\n",
    "• High Recall (minimize missed defaults - false negatives)\n",
    "• Interpretable feature importance for risk management\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: Data Understanding\n",
    "\n",
    "In this phase, we will:\n",
    "1. Load the dataset\n",
    "2. Explore the data structure\n",
    "3. Analyze missing values\n",
    "4. Examine the target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load Data Sample\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: DATA UNDERSTANDING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n2.1 Loading Data Sample...\")\n",
    "print(f\"    Reading sample of {SAMPLE_SIZE:,} rows from {DATA_PATH}...\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\n",
    "        DATA_PATH,\n",
    "        sep='|',\n",
    "        header=None,\n",
    "        names=COLUMN_NAMES,\n",
    "        nrows=SAMPLE_SIZE,\n",
    "        low_memory=False,\n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "    print(f\"    ✓ Successfully loaded {len(df):,} records with {df.shape[1]} columns\")\n",
    "except Exception as e:\n",
    "    print(f\"    ✗ Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Data Structure\n",
    "print(\"\\n2.2 Data Structure:\")\n",
    "print(f\"    Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"    Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n    Column Types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Analyze Column Data Availability\n",
    "print(\"\\n2.3 Analyzing Column Data Availability:\")\n",
    "\n",
    "col_data_counts = {}\n",
    "for col in df.columns:\n",
    "    non_null_count = df[col].notna().sum()\n",
    "    if non_null_count > 0:\n",
    "        col_data_counts[col] = non_null_count\n",
    "\n",
    "print(f\"    Columns with data: {len(col_data_counts)} out of {len(df.columns)}\")\n",
    "\n",
    "print(\"\\n    Top 15 columns with most data:\")\n",
    "sorted_cols = sorted(col_data_counts.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "for col, count in sorted_cols:\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"    - {col}: {count:,} records ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Sample Data Preview\n",
    "print(\"\\n2.4 Sample Data (First 10 rows, Key Columns):\")\n",
    "\n",
    "key_cols = ['loan_sequence_number', 'monthly_reporting_period', 'current_actual_upb', \n",
    "            'current_loan_delinquency', 'loan_age', 'current_interest_rate', 'estimated_ltv']\n",
    "\n",
    "available_key_cols = [c for c in key_cols if c in df.columns and df[c].notna().sum() > 0]\n",
    "\n",
    "if available_key_cols:\n",
    "    display(df[available_key_cols].head(10))\n",
    "else:\n",
    "    print(\"    Showing first 10 columns:\")\n",
    "    display(df.iloc[:10, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Target Variable Distribution\n",
    "print(\"\\n2.5 Target Variable Distribution (current_loan_delinquency):\")\n",
    "\n",
    "target_col = 'current_loan_delinquency'\n",
    "\n",
    "if target_col in df.columns:\n",
    "    delinq_dist = df[target_col].value_counts(dropna=False)\n",
    "    print(delinq_dist.head(20))\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    delinq_dist.head(10).plot(kind='bar', ax=ax, color='steelblue', edgecolor='black')\n",
    "    ax.set_title('Distribution of Loan Delinquency Status', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Delinquency Status')\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 3: Data Preparation\n",
    "\n",
    "In this phase, we will:\n",
    "1. Create the binary target variable (is_default)\n",
    "2. Select features for modeling\n",
    "3. Handle missing values\n",
    "4. Remove outliers\n",
    "5. Scale features\n",
    "6. Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Create Binary Target Variable\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 3: DATA PREPARATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n3.1 Creating Binary Target Variable (is_default)...\")\n",
    "\n",
    "def create_default_flag(status):\n",
    "    \"\"\"\n",
    "    Create binary default indicator:\n",
    "    - 0: No default (current or minor delinquency)\n",
    "    - 1: Default (90+ days delinquent or foreclosure)\n",
    "    \"\"\"\n",
    "    if pd.isna(status):\n",
    "        return np.nan\n",
    "    status_str = str(status).strip().upper()\n",
    "    \n",
    "    # Default conditions\n",
    "    if status_str in ['RA', 'XX', 'F', 'R', 'S', 'T', 'N', '09', '06']:\n",
    "        return 1\n",
    "    try:\n",
    "        if int(float(status_str)) >= 3:  # 90+ days delinquent\n",
    "            return 1\n",
    "    except:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "df['is_default'] = df['current_loan_delinquency'].apply(create_default_flag)\n",
    "\n",
    "default_dist = df['is_default'].value_counts(dropna=False)\n",
    "print(\"    Target Distribution:\")\n",
    "print(f\"    - No Default (0): {default_dist.get(0, 0):,} ({default_dist.get(0, 0)/len(df)*100:.2f}%)\")\n",
    "print(f\"    - Default (1): {default_dist.get(1, 0):,} ({default_dist.get(1, 0)/len(df)*100:.2f}%)\")\n",
    "print(f\"    - Missing: {df['is_default'].isna().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Feature Selection\n",
    "print(\"\\n3.2 Selecting Features for Modeling...\")\n",
    "\n",
    "feature_candidates = [\n",
    "    'current_actual_upb', 'loan_age', 'remaining_months_maturity',\n",
    "    'current_interest_rate', 'estimated_ltv', 'current_deferred_upb'\n",
    "]\n",
    "\n",
    "available_features = []\n",
    "for col in feature_candidates:\n",
    "    if col in df.columns:\n",
    "        numeric_vals = pd.to_numeric(df[col], errors='coerce')\n",
    "        valid_count = numeric_vals.notna().sum()\n",
    "        if valid_count > len(df) * 0.3:  # At least 30% valid\n",
    "            available_features.append(col)\n",
    "\n",
    "# Fallback to positional columns if needed\n",
    "if len(available_features) < 2:\n",
    "    print(\"    Named features not found. Using positional columns...\")\n",
    "    for i in [2, 4, 5, 10, 25, 11]:\n",
    "        if i < len(df.columns):\n",
    "            col = df.columns[i]\n",
    "            numeric_vals = pd.to_numeric(df[col], errors='coerce')\n",
    "            if numeric_vals.notna().sum() > len(df) * 0.3:\n",
    "                available_features.append(col)\n",
    "\n",
    "print(f\"    Selected features: {available_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Convert Features to Numeric\n",
    "print(\"\\n3.3 Converting Features to Numeric...\")\n",
    "\n",
    "df_model = df[available_features + ['is_default']].copy()\n",
    "\n",
    "for col in available_features:\n",
    "    df_model[col] = pd.to_numeric(df_model[col], errors='coerce')\n",
    "    valid_count = df_model[col].notna().sum()\n",
    "    print(f\"    - {col}: {valid_count:,} valid numeric values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Handle Missing Values\n",
    "print(\"\\n3.4 Handling Missing Values...\")\n",
    "\n",
    "# Remove rows with missing target\n",
    "df_model = df_model.dropna(subset=['is_default'])\n",
    "print(f\"    After removing missing targets: {len(df_model):,} records\")\n",
    "\n",
    "# Fill missing features with median\n",
    "for col in available_features:\n",
    "    missing_count = df_model[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        median_val = df_model[col].median()\n",
    "        if pd.notna(median_val):\n",
    "            df_model[col].fillna(median_val, inplace=True)\n",
    "            print(f\"    - Filled {col}: {missing_count:,} missing with median {median_val:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Remove Outliers and Invalid Values\n",
    "print(\"\\n3.5 Removing Outliers and Invalid Values...\")\n",
    "initial_count = len(df_model)\n",
    "\n",
    "# Remove infinite values\n",
    "df_model = df_model.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Remove extreme outliers (1st and 99th percentile)\n",
    "for col in available_features:\n",
    "    if df_model[col].dtype in ['int64', 'float64'] and len(df_model) > 0:\n",
    "        Q1 = df_model[col].quantile(0.01)\n",
    "        Q99 = df_model[col].quantile(0.99)\n",
    "        df_model = df_model[(df_model[col] >= Q1) & (df_model[col] <= Q99)]\n",
    "\n",
    "print(f\"    Removed {initial_count - len(df_model):,} outlier/invalid records\")\n",
    "print(f\"    Final dataset size: {len(df_model):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Feature Scaling\n",
    "print(\"\\n3.6 Feature Scaling (StandardScaler)...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = df_model[available_features].values\n",
    "y = df_model['is_default'].values.astype(int)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"    ✓ Features standardized (mean=0, std=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 Train-Test Split\n",
    "print(\"\\n3.7 Train-Test Split (80/20)...\")\n",
    "\n",
    "unique_classes = np.unique(y)\n",
    "print(f\"    Classes: {unique_classes}\")\n",
    "print(f\"    Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "# Use stratify if both classes present\n",
    "if len(unique_classes) > 1 and min(np.bincount(y)) > 1:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "print(f\"    Training set: {len(X_train):,} samples\")\n",
    "print(f\"    Test set: {len(X_test):,} samples\")\n",
    "print(f\"    Default rate (train): {y_train.mean()*100:.2f}%\")\n",
    "print(f\"    Default rate (test): {y_test.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 4: Modeling\n",
    "\n",
    "We will train and compare three classification models:\n",
    "1. **Logistic Regression** - Interpretable baseline\n",
    "2. **Random Forest** - Captures non-linear relationships\n",
    "3. **Gradient Boosting** - State-of-the-art performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4: Model Training\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 4: MODELING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=RANDOM_STATE, \n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=RANDOM_STATE,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=5,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "\n",
    "print(\"\\nTraining and Evaluating Models...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n>>> {model_name}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"    Training...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc_roc': auc_roc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"    Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"    Precision: {precision:.4f}\")\n",
    "    print(f\"    Recall:    {recall:.4f}\")\n",
    "    print(f\"    F1-Score:  {f1:.4f}\")\n",
    "    print(f\"    AUC-ROC:   {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 5: Evaluation\n",
    "\n",
    "In this phase, we will:\n",
    "1. Compare model performance\n",
    "2. Select the best model\n",
    "3. Analyze confusion matrix\n",
    "4. Examine feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Model Comparison Summary\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 5: EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n5.1 Model Comparison Summary:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    model_name: {\n",
    "        'Accuracy': res['accuracy'],\n",
    "        'Precision': res['precision'],\n",
    "        'Recall': res['recall'],\n",
    "        'F1-Score': res['f1_score'],\n",
    "        'AUC-ROC': res['auc_roc']\n",
    "    }\n",
    "    for model_name, res in results.items()\n",
    "}).T\n",
    "\n",
    "display(comparison_df.round(4).style.highlight_max(axis=0, color='lightgreen'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Best Model Selection\n",
    "best_model_name = comparison_df['AUC-ROC'].idxmax()\n",
    "best_model_auc = comparison_df['AUC-ROC'].max()\n",
    "print(f\"\\n5.2 Best Model: {best_model_name} (AUC-ROC: {best_model_auc:.4f})\")\n",
    "\n",
    "# 5.3 Confusion Matrix\n",
    "print(f\"\\n5.3 Confusion Matrix - {best_model_name}:\")\n",
    "best_results = results[best_model_name]\n",
    "cm = confusion_matrix(y_test, best_results['y_pred'])\n",
    "print(f\"    True Negatives:  {cm[0,0]:,}\")\n",
    "print(f\"    False Positives: {cm[0,1]:,}\")\n",
    "print(f\"    False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"    True Positives:  {cm[1,1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Classification Report\n",
    "print(f\"\\n5.4 Classification Report - {best_model_name}:\")\n",
    "print(classification_report(y_test, best_results['y_pred'], \n",
    "                          target_names=['No Default', 'Default']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Feature Importance\n",
    "print(\"\\n5.5 Feature Importance:\")\n",
    "\n",
    "feature_importance_df = None\n",
    "if hasattr(results[best_model_name]['model'], 'feature_importances_'):\n",
    "    importances = results[best_model_name]['model'].feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    display(feature_importance_df)\n",
    "elif hasattr(results[best_model_name]['model'], 'coef_'):\n",
    "    coefs = results[best_model_name]['model'].coef_[0]\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': available_features,\n",
    "        'Coefficient': coefs,\n",
    "        'Abs_Importance': np.abs(coefs)\n",
    "    }).sort_values('Abs_Importance', ascending=False)\n",
    "    display(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 6: Visualization & Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 6: Visualization\n",
    "print(\"=\"*80)\n",
    "print(\"PHASE 6: VISUALIZATION & REPORTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 6.1 ROC Curves\n",
    "ax1 = axes[0, 0]\n",
    "for model_name, res in results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, res['y_pred_proba'])\n",
    "    ax1.plot(fpr, tpr, label=f\"{model_name} (AUC={res['auc_roc']:.3f})\", linewidth=2)\n",
    "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "ax1.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax1.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax1.set_title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 6.2 Model Metrics Comparison\n",
    "ax2 = axes[0, 1]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "for i, (model_name, res) in enumerate(results.items()):\n",
    "    values = [res['accuracy'], res['precision'], res['recall'], res['f1_score'], res['auc_roc']]\n",
    "    ax2.bar(x + i*width, values, width, label=model_name, alpha=0.8, color=colors[i])\n",
    "\n",
    "ax2.set_xlabel('Metrics', fontsize=12)\n",
    "ax2.set_ylabel('Score', fontsize=12)\n",
    "ax2.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x + width)\n",
    "ax2.set_xticklabels(metrics, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 6.3 Confusion Matrix Heatmap\n",
    "ax3 = axes[1, 0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax3,\n",
    "            xticklabels=['No Default', 'Default'],\n",
    "            yticklabels=['No Default', 'Default'],\n",
    "            annot_kws={'size': 14})\n",
    "ax3.set_xlabel('Predicted', fontsize=12)\n",
    "ax3.set_ylabel('Actual', fontsize=12)\n",
    "ax3.set_title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 6.4 Feature Importance\n",
    "ax4 = axes[1, 1]\n",
    "if feature_importance_df is not None:\n",
    "    if 'Importance' in feature_importance_df.columns:\n",
    "        ax4.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='steelblue')\n",
    "    else:\n",
    "        ax4.barh(feature_importance_df['Feature'], feature_importance_df['Abs_Importance'], color='steelblue')\n",
    "    ax4.set_xlabel('Importance', fontsize=12)\n",
    "    ax4.set_title(f'Feature Importance - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('2008Q1_CRISP_DM_Results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualization saved: 2008Q1_CRISP_DM_Results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "print(\"\\nSaving Results...\")\n",
    "\n",
    "# Save model comparison\n",
    "comparison_df.to_csv('2008Q1_Model_Comparison.csv')\n",
    "print(\"✓ Model comparison saved: 2008Q1_Model_Comparison.csv\")\n",
    "\n",
    "# Generate Summary Report\n",
    "feature_importance_str = feature_importance_df.to_string(index=False) if feature_importance_df is not None else 'N/A'\n",
    "\n",
    "summary_report = f\"\"\"\n",
    "FANNIE MAE 2008Q1 STRESS TESTING - CREDIT DEFAULT PREDICTION\n",
    "=============================================================\n",
    "\n",
    "DATA OVERVIEW:\n",
    "--------------\n",
    "• Period: Q1 2008 (Financial Crisis Stress Period)\n",
    "• Sample Size: {len(df):,} records analyzed\n",
    "• Features Used: {', '.join(available_features)}\n",
    "• Target Variable: is_default (binary: 0=No Default, 1=Default)\n",
    "• Default Rate: {y.mean()*100:.2f}%\n",
    "• Clean Dataset Size: {len(df_model):,} records\n",
    "\n",
    "BEST MODEL: {best_model_name}\n",
    "---------------------------------\n",
    "• AUC-ROC:   {best_model_auc:.4f}\n",
    "• Accuracy:  {results[best_model_name]['accuracy']:.4f}\n",
    "• Precision: {results[best_model_name]['precision']:.4f}\n",
    "• Recall:    {results[best_model_name]['recall']:.4f}\n",
    "• F1-Score:  {results[best_model_name]['f1_score']:.4f}\n",
    "\n",
    "STRESS TEST INSIGHTS:\n",
    "---------------------\n",
    "1. Model achieves {'ACCEPTABLE' if best_model_auc >= 0.7 else 'BELOW TARGET'} \n",
    "   predictive power (AUC {'≥' if best_model_auc >= 0.7 else '<'} 0.70)\n",
    "   \n",
    "2. Key Risk Drivers (by importance):\n",
    "   {feature_importance_str}\n",
    "\n",
    "3. The model can identify {results[best_model_name]['recall']*100:.1f}% of actual defaults\n",
    "   (Recall metric - critical for risk management)\n",
    "\n",
    "CONFUSION MATRIX:\n",
    "-----------------\n",
    "True Negatives:  {cm[0,0]:,}\n",
    "False Positives: {cm[0,1]:,}\n",
    "False Negatives: {cm[1,0]:,}\n",
    "True Positives:  {cm[1,1]:,}\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "----------------\n",
    "1. Monitor loans with high-risk feature values identified above\n",
    "2. Implement early warning system for loans approaching delinquency\n",
    "3. Consider enhancing model with additional features (FICO score, LTV, DTI)\n",
    "4. Regular model recalibration with updated crisis data\n",
    "\n",
    "Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open('2008Q1_CRISP_DM_Report.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_report)\n",
    "print(\"✓ Summary report saved: 2008Q1_CRISP_DM_Report.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRISP-DM ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "1. **Dataset**: Analyzed 500,000 mortgage loan records from Q1 2008\n",
    "2. **Default Rate**: ~43% (high stress period)\n",
    "3. **Best Model**: Gradient Boosting with AUC-ROC of ~0.60\n",
    "4. **Key Risk Driver**: Current Deferred UPB (98% importance)\n",
    "\n",
    "## Recommendations for Improvement\n",
    "\n",
    "To improve model performance (target AUC > 0.70):\n",
    "\n",
    "1. **Add Acquisition Data Features**:\n",
    "   - Credit Score (FICO)\n",
    "   - Loan-to-Value (LTV)\n",
    "   - Debt-to-Income (DTI)\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Payment history patterns\n",
    "   - Time since last payment\n",
    "   - Geographic risk factors\n",
    "\n",
    "3. **Advanced Techniques**:\n",
    "   - Ensemble methods\n",
    "   - Time-series analysis\n",
    "   - Deep learning approaches\n",
    "\n",
    "---\n",
    "## Files Generated\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `2008Q1_CRISP_DM_Results.png` | Visualization dashboard |\n",
    "| `2008Q1_Model_Comparison.csv` | Model metrics comparison |\n",
    "| `2008Q1_CRISP_DM_Report.txt` | Summary report |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
