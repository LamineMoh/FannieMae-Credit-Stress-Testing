{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 6: Deployment\n",
                "\n",
                "## Fannie Mae 2008Q1 Stress Testing - Credit Default Risk Modeling\n",
                "\n",
                "---\n",
                "\n",
                "### CRISP-DM Phase 6: Generate Reports and Deploy Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "from datetime import datetime\n",
                "from sklearn.metrics import roc_curve\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "%matplotlib inline\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "\n",
                "print(\"Libraries imported successfully!\")\n",
                "print(f\"Report generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.1 Load Evaluation Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load evaluation data\n",
                "with open('phase5_evaluation.pkl', 'rb') as f:\n",
                "    eval_data = pickle.load(f)\n",
                "\n",
                "comparison_df = eval_data['comparison_df']\n",
                "best_model_name = eval_data['best_model_name']\n",
                "best_auc = eval_data['best_auc']\n",
                "cm = eval_data['confusion_matrix']\n",
                "feat_imp_df = eval_data['feature_importance_df']\n",
                "results = eval_data['results']\n",
                "y_test = eval_data['y_test']\n",
                "features = eval_data['features']\n",
                "\n",
                "print(f\"Best Model: {best_model_name}\")\n",
                "print(f\"Best AUC-ROC: {best_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.2 Create Final Dashboard"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comprehensive dashboard\n",
                "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
                "\n",
                "# 1. ROC Curves\n",
                "ax1 = axes[0, 0]\n",
                "colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6']\n",
                "for i, (model_name, res) in enumerate(results.items()):\n",
                "    fpr, tpr, _ = roc_curve(y_test, res['y_pred_proba'])\n",
                "    ax1.plot(fpr, tpr, label=f\"{model_name} (AUC={res['auc_roc']:.3f})\",\n",
                "            linewidth=2, color=colors[i % len(colors)])\n",
                "ax1.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
                "ax1.axhline(y=0.7, color='orange', linestyle=':', alpha=0.7, label='Target AUC=0.70')\n",
                "ax1.set_xlabel('False Positive Rate', fontsize=11)\n",
                "ax1.set_ylabel('True Positive Rate', fontsize=11)\n",
                "ax1.set_title('ROC Curves Comparison', fontsize=13, fontweight='bold')\n",
                "ax1.legend(loc='lower right', fontsize=9)\n",
                "ax1.grid(True, alpha=0.3)\n",
                "\n",
                "# 2. Model Metrics Comparison\n",
                "ax2 = axes[0, 1]\n",
                "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
                "x = np.arange(len(metrics))\n",
                "width = 0.2\n",
                "for i, (model_name, res) in enumerate(results.items()):\n",
                "    values = [res['accuracy'], res['precision'], res['recall'], res['f1_score'], res['auc_roc']]\n",
                "    ax2.bar(x + i*width, values, width, label=model_name, alpha=0.8, color=colors[i])\n",
                "ax2.axhline(y=0.70, color='red', linestyle='--', alpha=0.7, label='Target (0.70)')\n",
                "ax2.set_xlabel('Metrics', fontsize=11)\n",
                "ax2.set_ylabel('Score', fontsize=11)\n",
                "ax2.set_title('Model Performance Comparison', fontsize=13, fontweight='bold')\n",
                "ax2.set_xticks(x + width * 1.5)\n",
                "ax2.set_xticklabels(metrics, rotation=45)\n",
                "ax2.legend(loc='upper left', fontsize=8)\n",
                "ax2.set_ylim(0, 1.1)\n",
                "ax2.grid(True, alpha=0.3, axis='y')\n",
                "\n",
                "# 3. Confusion Matrix\n",
                "ax3 = axes[1, 0]\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax3,\n",
                "            xticklabels=['No Default', 'Default'],\n",
                "            yticklabels=['No Default', 'Default'],\n",
                "            annot_kws={'size': 14})\n",
                "ax3.set_xlabel('Predicted', fontsize=11)\n",
                "ax3.set_ylabel('Actual', fontsize=11)\n",
                "ax3.set_title(f'Confusion Matrix - {best_model_name}', fontsize=13, fontweight='bold')\n",
                "\n",
                "# 4. Feature Importance\n",
                "ax4 = axes[1, 1]\n",
                "if feat_imp_df is not None:\n",
                "    if 'Importance' in feat_imp_df.columns:\n",
                "        plot_df = feat_imp_df.nlargest(10, 'Importance')\n",
                "        ax4.barh(plot_df['Feature'], plot_df['Importance'], color='steelblue')\n",
                "    else:\n",
                "        plot_df = feat_imp_df.nlargest(10, 'Abs_Importance')\n",
                "        ax4.barh(plot_df['Feature'], plot_df['Abs_Importance'], color='steelblue')\n",
                "    ax4.set_xlabel('Importance', fontsize=11)\n",
                "    ax4.set_title(f'Top 10 Features - {best_model_name}', fontsize=13, fontweight='bold')\n",
                "    ax4.grid(True, alpha=0.3, axis='x')\n",
                "\n",
                "plt.suptitle('Fannie Mae 2008Q1 Stress Testing - Credit Default Prediction', \n",
                "             fontsize=16, fontweight='bold', y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.savefig('Final_Dashboard.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n✓ Dashboard saved to Final_Dashboard.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.3 Generate Final Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get best model results\n",
                "best_res = results[best_model_name]\n",
                "\n",
                "# Feature importance string\n",
                "if feat_imp_df is not None:\n",
                "    if 'Importance' in feat_imp_df.columns:\n",
                "        top_features = feat_imp_df.nlargest(5, 'Importance')[['Feature', 'Importance']].to_string(index=False)\n",
                "    else:\n",
                "        top_features = feat_imp_df.nlargest(5, 'Abs_Importance')[['Feature', 'Coefficient']].to_string(index=False)\n",
                "else:\n",
                "    top_features = 'N/A'\n",
                "\n",
                "# Generate report\n",
                "report = f\"\"\"\n",
                "================================================================================\n",
                "FANNIE MAE 2008Q1 STRESS TESTING - CREDIT DEFAULT PREDICTION\n",
                "CRISP-DM ANALYSIS FINAL REPORT\n",
                "================================================================================\n",
                "\n",
                "Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
                "\n",
                "================================================================================\n",
                "1. EXECUTIVE SUMMARY\n",
                "================================================================================\n",
                "\n",
                "This analysis applied the CRISP-DM methodology to predict mortgage loan defaults\n",
                "during Q1 2008, a critical period of the financial crisis.\n",
                "\n",
                "KEY RESULTS:\n",
                "• Best Model: {best_model_name}\n",
                "• AUC-ROC: {best_auc:.4f}\n",
                "• Target Achievement: {\"✓ ACHIEVED\" if best_auc >= 0.70 else \"✗ Below target (0.70)\"}\n",
                "\n",
                "================================================================================\n",
                "2. DATA OVERVIEW\n",
                "================================================================================\n",
                "\n",
                "• Period: Q1 2008 (Financial Crisis Stress Period)\n",
                "• Source: Fannie Mae Single-Family Loan Performance Data\n",
                "• Sample Size: 1,000,000 records\n",
                "• Features: {len(features)} engineered features\n",
                "• Target: is_default (binary: 0=No Default, 1=Default)\n",
                "\n",
                "================================================================================\n",
                "3. MODEL PERFORMANCE\n",
                "================================================================================\n",
                "\n",
                "{comparison_df.round(4).to_string()}\n",
                "\n",
                "BEST MODEL: {best_model_name}\n",
                "------------------------------------\n",
                "• AUC-ROC:   {best_res['auc_roc']:.4f}\n",
                "• Accuracy:  {best_res['accuracy']:.4f}\n",
                "• Precision: {best_res['precision']:.4f}\n",
                "• Recall:    {best_res['recall']:.4f}\n",
                "• F1-Score:  {best_res['f1_score']:.4f}\n",
                "\n",
                "================================================================================\n",
                "4. CONFUSION MATRIX\n",
                "================================================================================\n",
                "\n",
                "True Negatives (Correct No-Default):  {cm[0,0]:,}\n",
                "False Positives (False Alarms):       {cm[0,1]:,}\n",
                "False Negatives (Missed Defaults):    {cm[1,0]:,}\n",
                "True Positives (Correct Defaults):    {cm[1,1]:,}\n",
                "\n",
                "================================================================================\n",
                "5. KEY RISK DRIVERS\n",
                "================================================================================\n",
                "\n",
                "Top 5 Features by Importance:\n",
                "{top_features}\n",
                "\n",
                "================================================================================\n",
                "6. RECOMMENDATIONS\n",
                "================================================================================\n",
                "\n",
                "1. RISK MONITORING:\n",
                "   - Monitor loans with high deferred UPB ratios\n",
                "   - Flag loans with accumulated delinquent interest\n",
                "   - Track high LTV loans (>80%) closely\n",
                "\n",
                "2. EARLY WARNING SYSTEM:\n",
                "   - Implement monthly scoring for all active loans\n",
                "   - Set threshold alerts for high-risk predictions\n",
                "   - Create intervention workflows for flagged loans\n",
                "\n",
                "3. MODEL IMPROVEMENT (if AUC < 0.70):\n",
                "   - Add Acquisition file features (FICO, original LTV, DTI)\n",
                "   - Include geographic risk factors (state, MSA)\n",
                "   - Engineer time-series features (payment history)\n",
                "   - Consider XGBoost or LightGBM for better performance\n",
                "\n",
                "================================================================================\n",
                "7. FILES GENERATED\n",
                "================================================================================\n",
                "\n",
                "• Phase1_Business_Understanding.ipynb\n",
                "• Phase2_Data_Understanding.ipynb\n",
                "• Phase3_Data_Preparation.ipynb\n",
                "• Phase4_Modeling.ipynb\n",
                "• Phase5_Evaluation.ipynb\n",
                "• Phase6_Deployment.ipynb\n",
                "• Final_Dashboard.png\n",
                "• Final_Report.txt\n",
                "\n",
                "================================================================================\n",
                "END OF REPORT\n",
                "================================================================================\n",
                "\"\"\"\n",
                "\n",
                "# Display report\n",
                "print(report)\n",
                "\n",
                "# Save report\n",
                "with open('Final_Report.txt', 'w', encoding='utf-8') as f:\n",
                "    f.write(report)\n",
                "\n",
                "print(\"\\n✓ Report saved to Final_Report.txt\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6.4 Save Model Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save comparison to CSV\n",
                "comparison_df.to_csv('Model_Comparison.csv')\n",
                "print(\"✓ Model comparison saved to Model_Comparison.csv\")\n",
                "\n",
                "# Display final comparison\n",
                "print(\"\\nFinal Model Comparison:\")\n",
                "display(comparison_df.round(4).style.highlight_max(axis=0, color='lightgreen'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "# ✅ CRISP-DM Analysis Complete!\n",
                "\n",
                "## Summary\n",
                "\n",
                "This project successfully implemented the complete CRISP-DM methodology for credit\n",
                "default prediction during the 2008 financial crisis stress period.\n",
                "\n",
                "### Phases Completed:\n",
                "1. ✅ **Business Understanding** - Defined objectives and success criteria\n",
                "2. ✅ **Data Understanding** - Explored and analyzed Fannie Mae data\n",
                "3. ✅ **Data Preparation** - Cleaned data and engineered features\n",
                "4. ✅ **Modeling** - Trained 4 classification models\n",
                "5. ✅ **Evaluation** - Compared performance and analyzed results\n",
                "6. ✅ **Deployment** - Generated reports and visualizations\n",
                "\n",
                "### Deliverables:\n",
                "- 6 Jupyter Notebooks (one per CRISP-DM phase)\n",
                "- Final Dashboard visualization\n",
                "- Comprehensive text report\n",
                "- Model comparison CSV\n",
                "\n",
                "---\n",
                "*Analysis completed using Python, scikit-learn, and the CRISP-DM methodology.*"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}