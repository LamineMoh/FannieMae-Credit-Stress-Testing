{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 3: Data Preparation\n",
                "\n",
                "## Fannie Mae 2008Q1 Stress Testing - Credit Default Risk Modeling\n",
                "\n",
                "---\n",
                "\n",
                "### CRISP-DM Phase 3: Clean, Transform, and Engineer Features\n",
                "\n",
                "**Goal**: Prepare data with enhanced feature engineering to achieve AUC-ROC > 0.70"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
                "from sklearn.model_selection import train_test_split\n",
                "import pickle\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "RANDOM_STATE = 42\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.1 Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "DATA_PATH = \"2008Q1.csv\"\n",
                "SAMPLE_SIZE = 1000000\n",
                "\n",
                "# Column Names for Fannie Mae Performance File\n",
                "COLUMN_NAMES = [\n",
                "    'loan_sequence_number', 'monthly_reporting_period', 'current_actual_upb',\n",
                "    'current_loan_delinquency', 'loan_age', 'remaining_months_maturity',\n",
                "    'repurchase_flag', 'modification_flag', 'zero_balance_code', 'zero_balance_date',\n",
                "    'current_interest_rate', 'current_deferred_upb', 'due_date_last_paid',\n",
                "    'mi_recoveries', 'net_sales_proceeds', 'non_mi_recoveries', 'expenses',\n",
                "    'legal_costs', 'maintenance_costs', 'taxes_insurance_due', 'miscellaneous_expenses',\n",
                "    'actual_loss_calculation', 'modification_cost', 'step_modification_flag',\n",
                "    'deferred_payment_mod', 'estimated_ltv', 'zero_balance_removal_upb',\n",
                "    'delinquent_accrued_interest', 'delinquency_due_disaster', 'borrower_assistance_status'\n",
                "]\n",
                "\n",
                "# Add remaining columns for 110 total\n",
                "for i in range(30, 110):\n",
                "    COLUMN_NAMES.append(f'col_{i}')\n",
                "\n",
                "print(f\"Loading {SAMPLE_SIZE:,} rows from {DATA_PATH}...\")\n",
                "\n",
                "df = pd.read_csv(\n",
                "    DATA_PATH,\n",
                "    sep='|',\n",
                "    header=None,\n",
                "    names=COLUMN_NAMES,\n",
                "    nrows=SAMPLE_SIZE,\n",
                "    low_memory=False,\n",
                "    on_bad_lines='skip'\n",
                ")\n",
                "\n",
                "print(f\"✓ Loaded {len(df):,} records with {df.shape[1]} columns\")\n",
                "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.2 Create Target Variable"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_default_flag(status):\n",
                "    \"\"\"\n",
                "    Create binary default indicator:\n",
                "    - 0: No default (current or minor delinquency 0-2)\n",
                "    - 1: Default (90+ days delinquent, foreclosure, REO)\n",
                "    \"\"\"\n",
                "    if pd.isna(status):\n",
                "        return np.nan\n",
                "    status_str = str(status).strip().upper()\n",
                "    \n",
                "    # Default conditions\n",
                "    if status_str in ['RA', 'XX', 'F', 'R', 'S', 'T', 'N']:\n",
                "        return 1\n",
                "    try:\n",
                "        if int(float(status_str)) >= 3:\n",
                "            return 1\n",
                "    except:\n",
                "        pass\n",
                "    return 0\n",
                "\n",
                "print(\"Creating target variable...\")\n",
                "df['is_default'] = df['current_loan_delinquency'].apply(create_default_flag)\n",
                "\n",
                "default_dist = df['is_default'].value_counts(dropna=False)\n",
                "print(\"\\nTarget Distribution:\")\n",
                "print(f\"  No Default (0): {default_dist.get(0, 0):,} ({default_dist.get(0, 0)/len(df)*100:.2f}%)\")\n",
                "print(f\"  Default (1): {default_dist.get(1, 0):,} ({default_dist.get(1, 0)/len(df)*100:.2f}%)\")\n",
                "print(f\"  Missing: {df['is_default'].isna().sum():,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.3 Convert Columns to Numeric"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define columns to convert to numeric\n",
                "numeric_cols = [\n",
                "    'current_actual_upb', 'loan_age', 'remaining_months_maturity',\n",
                "    'current_interest_rate', 'current_deferred_upb', 'estimated_ltv',\n",
                "    'delinquent_accrued_interest', 'expenses', 'legal_costs',\n",
                "    'maintenance_costs', 'taxes_insurance_due'\n",
                "]\n",
                "\n",
                "print(\"Converting columns to numeric...\\n\")\n",
                "for col in numeric_cols:\n",
                "    if col in df.columns:\n",
                "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
                "        valid_count = df[col].notna().sum()\n",
                "        print(f\"  {col}: {valid_count:,} valid values ({valid_count/len(df)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.4 Feature Engineering\n",
                "\n",
                "### Strategy for 70% AUC:\n",
                "- Create derived features (ratios, flags)\n",
                "- Handle NaN values properly before creating flags"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Creating engineered features...\\n\")\n",
                "\n",
                "# 1. UPB to Deferred Ratio (high ratio = higher risk)\n",
                "# Fill NaN with 0 to avoid NaN in calculation\n",
                "upb = df['current_actual_upb'].fillna(0)\n",
                "deferred = df['current_deferred_upb'].fillna(0)\n",
                "df['upb_deferred_ratio'] = deferred / (upb + 1)\n",
                "print(\"  ✓ upb_deferred_ratio\")\n",
                "\n",
                "# 2. Loan Maturity Progress (how far into the loan)\n",
                "loan_age = df['loan_age'].fillna(0)\n",
                "remaining = df['remaining_months_maturity'].fillna(360)\n",
                "df['loan_progress'] = loan_age / (loan_age + remaining + 1)\n",
                "print(\"  ✓ loan_progress\")\n",
                "\n",
                "# 3. Interest Rate Stress (higher rates = higher risk during crisis)\n",
                "interest_rate = df['current_interest_rate'].fillna(df['current_interest_rate'].median())\n",
                "df['high_interest_flag'] = (interest_rate > 6.5).astype(int)\n",
                "print(\"  ✓ high_interest_flag\")\n",
                "\n",
                "# 4. Has Deferred UPB (binary flag)\n",
                "df['has_deferred_upb'] = (deferred > 0).astype(int)\n",
                "print(\"  ✓ has_deferred_upb\")\n",
                "\n",
                "# 5. Modification Flag (loans that were modified)\n",
                "df['is_modified'] = df['modification_flag'].apply(\n",
                "    lambda x: 1 if str(x).strip().upper() == 'Y' else 0\n",
                ")\n",
                "print(\"  ✓ is_modified\")\n",
                "\n",
                "# 6. Has Accrued Interest (delinquent interest accumulating)\n",
                "accrued = df['delinquent_accrued_interest'].fillna(0)\n",
                "df['has_accrued_interest'] = (accrued > 0).astype(int)\n",
                "print(\"  ✓ has_accrued_interest\")\n",
                "\n",
                "# 7. Total Expenses (sum of all expense columns)\n",
                "expense_cols = ['expenses', 'legal_costs', 'maintenance_costs', 'taxes_insurance_due']\n",
                "for col in expense_cols:\n",
                "    if col in df.columns:\n",
                "        df[col] = df[col].fillna(0)\n",
                "df['total_expenses'] = df[expense_cols].sum(axis=1)\n",
                "df['has_expenses'] = (df['total_expenses'] > 0).astype(int)\n",
                "print(\"  ✓ total_expenses\")\n",
                "print(\"  ✓ has_expenses\")\n",
                "\n",
                "# 8. LTV Risk Category\n",
                "ltv = df['estimated_ltv'].fillna(80)\n",
                "df['high_ltv_flag'] = (ltv > 80).astype(int)\n",
                "print(\"  ✓ high_ltv_flag\")\n",
                "\n",
                "# 9. UPB Risk Categories\n",
                "df['large_loan_flag'] = (upb > 300000).astype(int)\n",
                "print(\"  ✓ large_loan_flag\")\n",
                "\n",
                "# 10. Loan Age Risk (newer loans might be higher risk)\n",
                "df['new_loan_flag'] = (loan_age < 24).astype(int)\n",
                "print(\"  ✓ new_loan_flag\")\n",
                "\n",
                "print(\"\\n✓ All 11 engineered features created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.5 Select Features for Modeling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define feature set - 18 features total\n",
                "all_features = [\n",
                "    # Original numeric features (8)\n",
                "    'current_actual_upb',\n",
                "    'loan_age',\n",
                "    'remaining_months_maturity', \n",
                "    'current_interest_rate',\n",
                "    'current_deferred_upb',\n",
                "    'estimated_ltv',\n",
                "    'delinquent_accrued_interest',\n",
                "    'total_expenses',\n",
                "    \n",
                "    # Engineered features (10)\n",
                "    'upb_deferred_ratio',\n",
                "    'loan_progress',\n",
                "    'high_interest_flag',\n",
                "    'has_deferred_upb',\n",
                "    'is_modified',\n",
                "    'has_accrued_interest',\n",
                "    'has_expenses',\n",
                "    'high_ltv_flag',\n",
                "    'large_loan_flag',\n",
                "    'new_loan_flag'\n",
                "]\n",
                "\n",
                "# Check which features are available\n",
                "available_features = [f for f in all_features if f in df.columns]\n",
                "print(f\"Available features: {len(available_features)} of {len(all_features)}\")\n",
                "print(\"\\nFeatures:\")\n",
                "for i, f in enumerate(available_features, 1):\n",
                "    print(f\"  {i:2d}. {f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.6 Create Modeling Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create modeling dataframe\n",
                "print(\"Creating modeling dataset...\\n\")\n",
                "\n",
                "df_model = df[available_features + ['is_default']].copy()\n",
                "print(f\"Initial size: {len(df_model):,} records\")\n",
                "\n",
                "# Remove rows with missing target\n",
                "df_model = df_model.dropna(subset=['is_default'])\n",
                "print(f\"After removing missing targets: {len(df_model):,} records\")\n",
                "\n",
                "# Fill missing numeric features with median\n",
                "print(\"\\nFilling missing values:\")\n",
                "for col in available_features:\n",
                "    missing = df_model[col].isnull().sum()\n",
                "    if missing > 0:\n",
                "        median_val = df_model[col].median()\n",
                "        if pd.notna(median_val):\n",
                "            df_model[col] = df_model[col].fillna(median_val)\n",
                "            print(f\"  {col}: filled {missing:,} with median {median_val:.2f}\")\n",
                "        else:\n",
                "            df_model[col] = df_model[col].fillna(0)\n",
                "            print(f\"  {col}: filled {missing:,} with 0\")\n",
                "\n",
                "# Remove infinite values\n",
                "df_model = df_model.replace([np.inf, -np.inf], np.nan).dropna()\n",
                "print(f\"\\nAfter removing infinite values: {len(df_model):,} records\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.7 Handle Outliers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove extreme outliers (1st and 99th percentile) for continuous features\n",
                "print(\"Removing outliers...\\n\")\n",
                "initial_count = len(df_model)\n",
                "\n",
                "continuous_features = [\n",
                "    'current_actual_upb', 'loan_age', 'remaining_months_maturity',\n",
                "    'current_interest_rate', 'current_deferred_upb', 'estimated_ltv',\n",
                "    'delinquent_accrued_interest', 'total_expenses', 'upb_deferred_ratio'\n",
                "]\n",
                "\n",
                "for col in continuous_features:\n",
                "    if col in df_model.columns and len(df_model) > 0:\n",
                "        Q1 = df_model[col].quantile(0.01)\n",
                "        Q99 = df_model[col].quantile(0.99)\n",
                "        before = len(df_model)\n",
                "        df_model = df_model[(df_model[col] >= Q1) & (df_model[col] <= Q99)]\n",
                "        removed = before - len(df_model)\n",
                "        if removed > 0:\n",
                "            print(f\"  {col}: removed {removed:,} outliers\")\n",
                "\n",
                "print(f\"\\nTotal outliers removed: {initial_count - len(df_model):,}\")\n",
                "print(f\"Final clean dataset: {len(df_model):,} records\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.8 Feature Scaling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare features and target\n",
                "print(\"Scaling features...\\n\")\n",
                "\n",
                "X = df_model[available_features].values\n",
                "y = df_model['is_default'].values.astype(int)\n",
                "\n",
                "# Check for any remaining issues\n",
                "print(f\"X shape: {X.shape}\")\n",
                "print(f\"y shape: {y.shape}\")\n",
                "print(f\"X contains NaN: {np.isnan(X).any()}\")\n",
                "print(f\"X contains Inf: {np.isinf(X).any()}\")\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "print(\"\\n✓ Features scaled successfully!\")\n",
                "print(f\"\\nClass distribution:\")\n",
                "print(f\"  No Default (0): {(y==0).sum():,} ({(y==0).sum()/len(y)*100:.2f}%)\")\n",
                "print(f\"  Default (1): {(y==1).sum():,} ({(y==1).sum()/len(y)*100:.2f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.9 Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split data with stratification\n",
                "print(\"Splitting data into train/test sets...\\n\")\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_scaled, y, \n",
                "    test_size=0.2, \n",
                "    random_state=RANDOM_STATE, \n",
                "    stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Training set: {len(X_train):,} samples ({len(X_train)/len(X_scaled)*100:.0f}%)\")\n",
                "print(f\"Test set: {len(X_test):,} samples ({len(X_test)/len(X_scaled)*100:.0f}%)\")\n",
                "print(f\"\\nDefault rate (train): {y_train.mean()*100:.2f}%\")\n",
                "print(f\"Default rate (test): {y_test.mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3.10 Save Prepared Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save prepared data for Phase 4\n",
                "prepared_data = {\n",
                "    'X_train': X_train,\n",
                "    'X_test': X_test,\n",
                "    'y_train': y_train,\n",
                "    'y_test': y_test,\n",
                "    'features': available_features,\n",
                "    'scaler': scaler,\n",
                "    'df_model': df_model\n",
                "}\n",
                "\n",
                "with open('phase3_prepared_data.pkl', 'wb') as f:\n",
                "    pickle.dump(prepared_data, f)\n",
                "\n",
                "print(\"✓ Prepared data saved to phase3_prepared_data.pkl\")\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"PHASE 3 SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Total features: {len(available_features)}\")\n",
                "print(f\"Training samples: {len(X_train):,}\")\n",
                "print(f\"Test samples: {len(X_test):,}\")\n",
                "print(f\"Default rate: {y.mean()*100:.2f}%\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ✅ Phase 3 Complete!\n",
                "\n",
                "### Key Improvements for 70% AUC:\n",
                "- Sample size: 1,000,000 records\n",
                "- 18 total features (8 original + 10 engineered)\n",
                "- Proper NaN handling before feature engineering\n",
                "- Outlier removal (1st-99th percentile)\n",
                "- StandardScaler for feature normalization\n",
                "\n",
                "### Next: Phase 4 - Modeling\n",
                "\n",
                "Run the next notebook: `Phase4_Modeling.ipynb`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}