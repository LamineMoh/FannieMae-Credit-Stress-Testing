{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 4: Modeling\n",
                "\n",
                "## Fannie Mae 2008Q1 Stress Testing - Credit Default Risk Modeling\n",
                "\n",
                "---\n",
                "\n",
                "### CRISP-DM Phase 4: Train Classification Models\n",
                "\n",
                "**Goal**: Train multiple models to achieve AUC-ROC > 0.70"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import numpy as np\n",
                "import pickle\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, \n",
                "    f1_score, roc_auc_score\n",
                ")\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "RANDOM_STATE = 42\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.1 Load Prepared Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data from Phase 3\n",
                "with open('phase3_prepared_data.pkl', 'rb') as f:\n",
                "    data = pickle.load(f)\n",
                "\n",
                "X_train = data['X_train']\n",
                "X_test = data['X_test']\n",
                "y_train = data['y_train']\n",
                "y_test = data['y_test']\n",
                "features = data['features']\n",
                "\n",
                "print(f\"Training set: {len(X_train):,} samples\")\n",
                "print(f\"Test set: {len(X_test):,} samples\")\n",
                "print(f\"Features: {len(features)}\")\n",
                "print(f\"Default rate: {y_train.mean()*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.2 Define Models\n",
                "\n",
                "We'll train 4 models with optimized parameters for credit risk prediction:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define models with optimized parameters\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(\n",
                "        random_state=RANDOM_STATE, \n",
                "        max_iter=1000,\n",
                "        class_weight='balanced',\n",
                "        C=0.1,  # Regularization\n",
                "        solver='lbfgs'\n",
                "    ),\n",
                "    \n",
                "    'Random Forest': RandomForestClassifier(\n",
                "        n_estimators=200,\n",
                "        max_depth=15,\n",
                "        min_samples_split=10,\n",
                "        min_samples_leaf=5,\n",
                "        random_state=RANDOM_STATE,\n",
                "        class_weight='balanced',\n",
                "        n_jobs=-1\n",
                "    ),\n",
                "    \n",
                "    'Gradient Boosting': GradientBoostingClassifier(\n",
                "        n_estimators=200,\n",
                "        max_depth=6,\n",
                "        learning_rate=0.1,\n",
                "        min_samples_split=10,\n",
                "        min_samples_leaf=5,\n",
                "        subsample=0.8,\n",
                "        random_state=RANDOM_STATE\n",
                "    ),\n",
                "    \n",
                "    'Neural Network (MLP)': MLPClassifier(\n",
                "        hidden_layer_sizes=(100, 50),\n",
                "        activation='relu',\n",
                "        solver='adam',\n",
                "        alpha=0.001,\n",
                "        batch_size=256,\n",
                "        learning_rate='adaptive',\n",
                "        max_iter=200,\n",
                "        random_state=RANDOM_STATE\n",
                "    )\n",
                "}\n",
                "\n",
                "print(f\"Defined {len(models)} models for training:\")\n",
                "for name in models:\n",
                "    print(f\"  - {name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.3 Train and Evaluate Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train and evaluate each model\n",
                "results = {}\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"TRAINING MODELS\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "for model_name, model in models.items():\n",
                "    print(f\"\\n>>> {model_name}\")\n",
                "    print(\"    Training...\")\n",
                "    \n",
                "    # Train\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # Predict\n",
                "    y_pred = model.predict(X_test)\n",
                "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    # Metrics\n",
                "    metrics = {\n",
                "        'model': model,\n",
                "        'accuracy': accuracy_score(y_test, y_pred),\n",
                "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
                "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
                "        'f1_score': f1_score(y_test, y_pred, zero_division=0),\n",
                "        'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
                "        'y_pred': y_pred,\n",
                "        'y_pred_proba': y_pred_proba\n",
                "    }\n",
                "    \n",
                "    results[model_name] = metrics\n",
                "    \n",
                "    # Display results\n",
                "    print(f\"    Accuracy:  {metrics['accuracy']:.4f}\")\n",
                "    print(f\"    Precision: {metrics['precision']:.4f}\")\n",
                "    print(f\"    Recall:    {metrics['recall']:.4f}\")\n",
                "    print(f\"    F1-Score:  {metrics['f1_score']:.4f}\")\n",
                "    print(f\"    AUC-ROC:   {metrics['auc_roc']:.4f}\")\n",
                "    \n",
                "    # Check if target achieved\n",
                "    if metrics['auc_roc'] >= 0.70:\n",
                "        print(f\"    ‚úì TARGET ACHIEVED (AUC ‚â• 0.70)\")\n",
                "    else:\n",
                "        print(f\"    ‚úó Below target (need {0.70 - metrics['auc_roc']:.4f} more)\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"TRAINING COMPLETE\")\n",
                "print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4.4 Results Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Create comparison table\n",
                "comparison_df = pd.DataFrame({\n",
                "    model_name: {\n",
                "        'Accuracy': res['accuracy'],\n",
                "        'Precision': res['precision'],\n",
                "        'Recall': res['recall'],\n",
                "        'F1-Score': res['f1_score'],\n",
                "        'AUC-ROC': res['auc_roc']\n",
                "    }\n",
                "    for model_name, res in results.items()\n",
                "}).T\n",
                "\n",
                "print(\"\\nModel Comparison:\")\n",
                "comparison_df.round(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find best model\n",
                "best_model_name = comparison_df['AUC-ROC'].idxmax()\n",
                "best_auc = comparison_df['AUC-ROC'].max()\n",
                "\n",
                "print(f\"\\nBest Model: {best_model_name}\")\n",
                "print(f\"Best AUC-ROC: {best_auc:.4f}\")\n",
                "\n",
                "if best_auc >= 0.70:\n",
                "    print(\"\\nüéâ SUCCESS! Target AUC-ROC ‚â• 0.70 achieved!\")\n",
                "else:\n",
                "    print(f\"\\n‚ö†Ô∏è Target not reached. Need additional features or tuning.\")\n",
                "    print(f\"   Gap to target: {0.70 - best_auc:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results for Phase 5\n",
                "phase4_results = {\n",
                "    'results': results,\n",
                "    'comparison_df': comparison_df,\n",
                "    'best_model_name': best_model_name,\n",
                "    'y_test': y_test,\n",
                "    'features': features\n",
                "}\n",
                "\n",
                "with open('phase4_results.pkl', 'wb') as f:\n",
                "    pickle.dump(phase4_results, f)\n",
                "\n",
                "print(\"\\n‚úì Results saved to phase4_results.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úÖ Phase 4 Complete\n",
                "\n",
                "**Models Trained**:\n",
                "1. Logistic Regression (balanced, regularized)\n",
                "2. Random Forest (200 trees, max_depth=15)\n",
                "3. Gradient Boosting (200 trees, learning_rate=0.1)\n",
                "4. Neural Network MLP (2 hidden layers)\n",
                "\n",
                "**Next**: Phase 5 - Evaluation"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}